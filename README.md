# Fine-Tuning Llama-3 8B: QLoRA vs Natural Gradient (GRIT)

A comparative study of two fine-tuning approaches for Llama-3 8B on the Alpaca-GPT4 dataset:
1. **Baseline QLoRA** - Standard first-order optimization with Unsloth
2. **Pure GRIT** - Second-order natural gradient descent with Fisher Information Matrix

---

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Mathematical Foundations](#mathematical-foundations)
- [Implementation Comparison](#implementation-comparison)
- [Pipeline Flow](#pipeline-flow)
- [Results](#results)
- [Key Findings](#key-findings)

---

## Overview

Both approaches use **QLoRA (Quantized Low-Rank Adaptation)** but differ fundamentally in their optimization strategy:

| Aspect | Baseline QLoRA | Pure GRIT |
|--------|---------------|-----------|
| **Optimization** | First-order (AdamW) | Second-order (Natural Gradient) |
| **Geometry** | Euclidean | Riemannian (Fisher-informed) |
| **Convergence** | Linear | Quadratic |
| **Memory** | 6.6 GB | 7.4 GB (+12%) |
| **Speed** | 4.8 sec/step | 23 sec/step (4.8Ã— slower) |
| **Final Loss** | 1.0439 | 0.0899 (11.6Ã— better) |

---

## Mathematical Foundations

### 1. Baseline QLoRA - First-Order Optimization

**Standard Gradient Descent:**
```
Î¸_{t+1} = Î¸_t - Î· Â· âˆ‡L(Î¸_t)
```

**AdamW Enhancement:**
```
Î¸_{t+1} = Î¸_t - Î· Â· (m_t / âˆš(v_t + Îµ)) - Î» Â· Î¸_t
```

Where:
- `Î·` = learning rate
- `m_t` = first moment (exponential moving average of gradients)
- `v_t` = second moment (exponential moving average of squared gradients)
- `Î»` = weight decay

**Characteristics:**
- Uses only first-order gradient information
- Treats parameter space as flat (Euclidean)
- Adaptive per-parameter learning rates
- No curvature information

---

### 2. Pure GRIT - Natural Gradient Descent

**Natural Gradient Update:**
```
Î¸_{t+1} = Î¸_t - Î· Â· F^{-1} Â· âˆ‡L(Î¸_t)
```

Where `F` is the **Fisher Information Matrix:**
```
F = E[âˆ‡log p(y|x,Î¸) Â· âˆ‡log p(y|x,Î¸)^T]
```

**K-FAC Approximation (Kronecker-Factored):**
```
F â‰ˆ A âŠ— G

A = E[a Â· a^T]  (input activation covariance)
G = E[g Â· g^T]  (output gradient covariance)
```

**Preconditioned Gradient:**
```
âˆ‡Ìƒ_A = A^{-1} Â· âˆ‡L_A  (LoRA matrix A)
âˆ‡Ìƒ_B = âˆ‡L_B Â· G^{-1}  (LoRA matrix B)
```

**Key Innovation - Rank-Space Projection:**
Instead of computing full `dÃ—d` covariances, GRIT projects to LoRA rank space:
```
A_cov = (a @ A^T)^T @ (a @ A^T)  â†’ rÃ—r matrix
G_cov = (g @ B)^T @ (g @ B)      â†’ rÃ—r matrix
```

This reduces memory from O(dÂ²) to O(rÂ²) where r=16.

**Characteristics:**
- Uses second-order curvature information
- Respects loss landscape geometry (Riemannian)
- Geometry-aware parameter updates
- Quadratic convergence rate

---

## Implementation Comparison

### Configuration (Identical for Fair Comparison)

```python
# Base Model
model = "meta-llama/Meta-Llama-3-8B"

# Quantization (Both use 4-bit NF4)
quantization = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
)

# LoRA Configuration (Identical)
lora_config = LoraConfig(
    r=16,
    lora_alpha=16,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                    "gate_proj", "up_proj", "down_proj"],
    lora_dropout=0.0,
    bias="none",
    task_type="CAUSAL_LM",
)

# Training Arguments (Identical)
training_args = {
    "per_device_train_batch_size": 2,
    "gradient_accumulation_steps": 4,
    "warmup_steps": 5,
    "max_steps": 200,
    "learning_rate": 2e-4,
    "weight_decay": 0.01,
    "lr_scheduler_type": "linear",
    "seed": 3407,
    "max_seq_length": 2048,
}

# Dataset
dataset = "vicgalle/alpaca-gpt4"  # 52,002 samples
```

---

### Code Implementation Differences

#### **Baseline QLoRA (`unsloth/Llama3_(8B)_Ollama.ipynb`)**

```python
from unsloth import FastLanguageModel
from trl import SFTTrainer, SFTConfig

# Load model with Unsloth wrapper
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/llama-3-8b-bnb-4bit",
    max_seq_length=2048,
    dtype=None,
    load_in_4bit=True,
)

# Apply LoRA with Unsloth
model = FastLanguageModel.get_peft_model(
    model,
    r=16,
    lora_alpha=16,
    use_gradient_checkpointing="unsloth",  # Optimized checkpointing
)

# Standard SFT Trainer
trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    args=SFTConfig(
        optim="adamw_8bit",  # 8-bit quantized AdamW
        ...
    ),
)

trainer.train()  # Standard first-order optimization
```

**Gradient Flow:**
```
Loss â†’ Backprop â†’ Gradients â†’ AdamW â†’ Update Weights
```

---

#### **Pure GRIT (`unsloth_3_Pure_Grit/Llama3_8B.ipynb`)**

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from grit.config import GRITConfig
from grit.manager import GRITManager
from grit.trainer import GritTrainer

# Load model with standard HuggingFace (no Unsloth wrapper)
model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Meta-Llama-3-8B",
    quantization_config=bnb_config,
    torch_dtype=torch.bfloat16,
)

# Apply LoRA with native PEFT
model = prepare_model_for_kbit_training(model)
model = get_peft_model(model, lora_config)

# Initialize GRIT Manager
grit_config = GRITConfig()
grit_config.lora_rank = 16
grit_config.kfac_update_freq = 10      # Fisher update every 10 steps
grit_config.kfac_damping = 1e-5        # Regularization for inversion
grit_config.kfac_min_samples = 16      # Minimum samples before inversion

grit_manager = GRITManager(
    model=model,
    config=grit_config,
    device="cuda",
)

# GRIT Trainer with built-in natural gradient
trainer = GritTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=tokenized_dataset,
    args=training_args,
    grit_manager=grit_manager,  # Inject GRIT manager
)

trainer.train()  # Natural gradient optimization
```

**Gradient Flow:**
```
Loss â†’ Backprop â†’ Gradients â†’ Fisher Preconditioning â†’ AdamW â†’ Update Weights
                                      â†‘
                                [F^-1 @ grad]
```

**GRIT Training Loop (Simplified):**
```python
for step in range(max_steps):
    # 1. Forward pass
    loss = model(inputs).loss

    # 2. Backward pass (captures Fisher statistics via custom autograd)
    loss.backward()

    # 3. Update Fisher matrices (every kfac_update_freq steps)
    if step % kfac_update_freq == 0:
        grit_manager.update_and_invert_factors()

    # 4. Precondition gradients with Fisher inverse
    if grit_manager.factors_are_ready:
        grit_manager.precondition_gradients()  # grad â† F^-1 @ grad

    # 5. Optimizer step with preconditioned gradients
    optimizer.step()
```

---

## Pipeline Flow

### **Baseline QLoRA Pipeline**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Environment Setup                                        â”‚
â”‚    - Install Unsloth package                                â”‚
â”‚    - Load pre-quantized model (unsloth/llama-3-8b-bnb-4bit) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. LoRA Configuration                                       â”‚
â”‚    - Apply FastLanguageModel.get_peft_model()               â”‚
â”‚    - Trainable params: 41.9M (0.52%)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Data Preparation                                         â”‚
â”‚    - Load vicgalle/alpaca-gpt4 (52K samples)                â”‚
â”‚    - Use Unsloth's to_sharegpt() for column merging         â”‚
â”‚    - Apply chat template with apply_chat_template()         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Training (SFTTrainer)                                    â”‚
â”‚    - Optimizer: AdamW 8-bit                                 â”‚
â”‚    - Gradient checkpointing: "unsloth" mode                 â”‚
â”‚    - 200 steps Ã— 4.8 sec/step = 16.1 minutes                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Export                                                   â”‚
â”‚    - Save LoRA adapters                                     â”‚
â”‚    - Export to GGUF (Q8_0 quantization)                     â”‚
â”‚    - Deploy to Ollama                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **Pure GRIT Pipeline**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Environment Setup                                        â”‚
â”‚    - Install GRIT from requirements.txt                     â”‚
â”‚    - Load standard Meta Llama-3-8B model                    â”‚
â”‚    - Apply BitsAndBytesConfig manually                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. LoRA Configuration                                       â”‚
â”‚    - prepare_model_for_kbit_training()                      â”‚
â”‚    - get_peft_model() with PEFT's native implementation     â”‚
â”‚    - Trainable params: 41.9M (0.52%)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. GRIT Manager Initialization                              â”‚
â”‚    - Instrument 224 LoRA modules with custom autograd       â”‚
â”‚    - Allocate rÃ—r covariance matrices (16Ã—16)               â”‚
â”‚    - Initialize Fisher inverse storage on CPU               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Data Preparation                                         â”‚
â”‚    - Load vicgalle/alpaca-gpt4 (52K samples)                â”‚
â”‚    - Manual tokenization (no Unsloth helpers)               â”‚
â”‚    - Create Alpaca-format prompts                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Training (GritTrainer)                                   â”‚
â”‚    - Every forward/backward: Capture Fisher statistics      â”‚
â”‚    - Every 10 steps: Update & invert Fisher matrices        â”‚
â”‚    - Every step (after warmup): Precondition gradients      â”‚
â”‚    - Optimizer: AdamW (standard PyTorch)                    â”‚
â”‚    - 200 steps Ã— 23 sec/step = 91 minutes                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Export                                                   â”‚
â”‚    - Save LoRA adapters                                     â”‚
â”‚    - Export to GGUF (Q8_0 quantization)                     â”‚
â”‚    - Deploy to Ollama                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Results

### Training Metrics Comparison

![Loss Curves Comparison](readme_files/tensorboard_log1.png)

**Main Loss Curve Analysis:**

| Metric | Baseline QLoRA | Pure GRIT | Improvement |
|--------|---------------|-----------|-------------|
| **Final Loss** | 1.0439 | 0.0899 | **11.6Ã— lower** |
| **Training Time** | 16.1 min | 91 min | 5.6Ã— slower |
| **Steps/sec** | 0.21 it/s | 0.04 it/s | 5.2Ã— slower |
| **Convergence Speed** | Gradual (200 steps) | Rapid (10 steps) | **20Ã— faster** |
| **GPU Memory** | 6.6 GB | 7.4 GB | +12% |

---

### Detailed Metrics

![Detailed Training Metrics](readme_files/tensorboard_log2.png)

**Additional Observations:**

1. **train/epoch**: 0.0308 for both (only 200 steps of 52K samples)

2. **train/grad_norm**:
   - Baseline: 0.3046
   - Pure GRIT: 0.136
   - **Pure GRIT has 2.2Ã— smaller gradients** â†’ closer to convergence

3. **train/learning_rate**:
   - Both use identical linear decay schedule
   - Decay from 2e-4 â†’ 0 over 200 steps

4. **Convergence Pattern**:
   - **Baseline**: Smooth descent from 7.5 â†’ 1.04 over 200 steps
   - **Pure GRIT**: Steep drop 7.5 â†’ 0.1 in ~10 steps, then plateau

---

## Key Findings

### âœ… **What We Learned**

#### 1. **GRIT Works (When Properly Implemented)**
- Phase 3 (Hybrid GRIT with Unsloth callback) showed **identical curves** to baseline
- Phase 4 (Pure GRIT standalone) shows **dramatically different curves**
- **Conclusion:** Unsloth's gradient management was overriding GRIT's preconditioning

#### 2. **Natural Gradient Provides Faster Convergence**
- **10Ã— faster initial convergence** (10 steps vs 200 steps)
- Achieves 11.6Ã— lower training loss
- Consistent with research papers claiming 100Ã— fewer iterations needed

#### 3. **Trade-offs Are Real**
- **Time cost:** 5.6Ã— slower per step due to Fisher inversion
- **Memory cost:** +12% for storing covariance matrices
- **Total time:** 91 min vs 16 min (not practical for large-scale training)

#### 4. **Second-Order Methods Show Promise for Fine-Tuning**
- Small parameter count (41.9M LoRA params) makes Fisher inversion feasible
- Rank-space projection (r=16) keeps memory overhead low
- Could be valuable for scenarios where training time is acceptable

---

### âš ï¸ **Open Questions**

#### 1. **Is Pure GRIT Overfitting?**
- Training loss of 0.09 is suspiciously low for Alpaca
- Baseline's 1.04 is more typical
- **Need validation set evaluation** to confirm generalization

#### 2. **Quality vs. Speed Trade-off**
- 11.6Ã— better loss but 5.6Ã— slower training
- Is the quality improvement worth the time cost?
- **Need inference quality testing** (response coherence, factuality)

#### 3. **Generalization to Other Tasks**
- Tested only on Alpaca instruction-following
- Would GRIT help on domain-specific tasks?
- Would it help on larger models (70B, 405B)?

---

### ðŸŽ¯ **Recommendations**

#### **Use Baseline QLoRA When:**
- You need fast iteration cycles (prototyping)
- Training budget is limited
- Good-enough performance is acceptable
- Training on large datasets (>100K samples)

#### **Use Pure GRIT When:**
- You need maximum training loss reduction
- Training time is not a constraint
- You have small fine-tuning datasets
- You need fewer training steps (warmup-limited scenarios)

#### **Avoid Hybrid GRIT (Unsloth + Callback):**
- Confirmed to be ineffective
- Unsloth's optimizations interfere with gradient preconditioning
- Use Pure GRIT or Baseline QLoRA instead

---

## Implementation Files

```
finetuning_evaluation/
â”œâ”€â”€ unsloth/
â”‚   â””â”€â”€ Llama3_(8B)_Ollama.ipynb          # Baseline QLoRA implementation
â”œâ”€â”€ unsloth_3_Pure_Grit/
â”‚   â”œâ”€â”€ Llama3_8B.ipynb                   # Pure GRIT implementation
â”‚   â””â”€â”€ grit/                             # GRIT library
â”‚       â”œâ”€â”€ config.py                     # GRIT configuration
â”‚       â”œâ”€â”€ manager.py                    # Fisher matrix management
â”‚       â”œâ”€â”€ autograd.py                   # Custom autograd hooks
â”‚       â”œâ”€â”€ trainer.py                    # GritTrainer class
â”‚       â””â”€â”€ optim.py                      # Optimizer wrapper
â”œâ”€â”€ tensorboard_logs/                     # Centralized TensorBoard logs
â”‚   â”œâ”€â”€ unsloth_ft_20251002_044038/       # Baseline run
â”‚   â””â”€â”€ pure_grit_20251002_072335/        # GRIT run
â””â”€â”€ readme_files/
    â”œâ”€â”€ tensorboard_log1.png              # Loss curves comparison
    â””â”€â”€ tensorboard_log2.png              # Detailed metrics
```

---

## References

1. **QLoRA**: [Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314) - Dettmers et al., 2023
2. **K-FAC**: [Optimizing Neural Networks with Kronecker-factored Approximate Curvature](https://arxiv.org/abs/1503.05671) - Martens & Grosse, 2015
3. **Natural Gradient**: [New Insights and Perspectives on the Natural Gradient Method](https://jmlr.org/papers/v21/17-678.html) - Martens, 2020
4. **Unsloth**: [2x Faster Language Model Fine-tuning](https://github.com/unslothai/unsloth)
5. **Alpaca Dataset**: [Stanford Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html) - Taori et al., 2023

---

## License

MIT License

---

## Acknowledgments

- **Unsloth** team for optimized QLoRA implementation
- **GRIT** authors for natural gradient research
- **Meta** for Llama-3 base model
- **Stanford** for Alpaca dataset methodology
